{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccc-frankfurt/Practical_ML_SS21/blob/main/Naive_Bayes_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRcUNm8sWmdc"
      },
      "source": [
        "# Naive Bayes and SMS Spam Collection Dataset\n",
        "\n",
        "In this week we will use Naive Bayes (the assumption of feature independence in a probabilistic context) in order to accomplish a classification task of distinguishing spam from non-spam messages.\n",
        "\n",
        "We will use the kaggle SMS Spam Collection dataset for this purpose: https://www.kaggle.com/uciml/sms-spam-collection-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0TcfBsVaC6Y"
      },
      "source": [
        "First, let us import the packages that we will need. Notice that we are importing nltk - which is a Natural Language Toolkit which will aid us in preprocessing the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RqlUlHgkaeT"
      },
      "source": [
        "# please restart the runtime after running this cell (to use the versioned matplotlib)\n",
        "!pip install matplotlib==3.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui9qJOP7vcOL"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import string\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "!pip install wget\n",
        "import wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqVGT0TyzMqz"
      },
      "source": [
        "# download the data\n",
        "url = \"https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv\"\n",
        "data = wget.download(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGjVEheJaixA"
      },
      "source": [
        "We will convert the data into the pandas dataframe and remove the columns we do not need. We will add an additional column with labels, converted to integers (instead of strings 'spam' and 'ham')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N987w8dzvmmW"
      },
      "source": [
        "df = pd.read_csv('./spam.csv', encoding = 'latin-1')\n",
        "# delete columns with unuseful values\n",
        "df = df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1)\n",
        "df.columns = ['label', 'text']\n",
        "\n",
        "# convert string labels to integers\n",
        "df[\"label_int\"] = //TODO\n",
        "df.head(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT0slQajdLAw"
      },
      "source": [
        "As a preprocessing step, we have to clean the dataset. This is because not all sms-symbols are relevant for spam classification. For example, punctuation is not. Consider also that word endings, e.g. singular or plural, might hinder to recognize the word as the same (and update the count accordingly)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxgoDWLk9ikW"
      },
      "source": [
        "# the cleanTest function is from \n",
        "# https://www.kaggle.com/ishansoni/sms-spam-collection-dataset\n",
        "\n",
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def cleanText(message):\n",
        "    \n",
        "    # remove the punctuation from the messages\n",
        "    # hint1: use maketrans method of str\n",
        "    # hint2: you can get punctuation characters with string.punctuation (print those to check)\n",
        "    message = message.translate(//TODO)\n",
        "    # convert words in the message into their stems and remove stopwords\n",
        "    # also remove numbers hint: isdigit() method could be useful\n",
        "    words = [//TODO]\n",
        "    \n",
        "    return \" \".join(words)\n",
        "\n",
        "df[\"text\"] = df[\"text\"].apply(cleanText)\n",
        "df.head(n = 10)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i20gJjt2wW4N"
      },
      "source": [
        "Split the data into train and test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NipVNb5TF8RV"
      },
      "source": [
        "x = df[\"text\"]\n",
        "y = df[\"label_int\"]\n",
        "\n",
        "perm = np.random.permutation(len(x))\n",
        "\n",
        "split = 0.8\n",
        "\n",
        "x_train, x_test = x[perm[:int(split*len(x))]], x[perm[int(split*len(x)):]]\n",
        "y_train, y_test = y[perm[:int(split*len(y))]], y[perm[int(split*len(y)):]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zies0r53wbuV"
      },
      "source": [
        "Gather all spam words in a list and all ham words in another list. \n",
        "\n",
        "Hint: a message consists of words. Join the messages into a global string and then split them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzbIAt2ZPlfT"
      },
      "source": [
        "# 0 - ham, 1 - spam\n",
        "# select all train spam messages\n",
        "spam_messages = //TODO\n",
        "# join them and split into a list of single words\n",
        "spam_words = //TODO\n",
        "print(spam_words)\n",
        "\n",
        "# repeat for ham messages\n",
        "ham_messages = //TODO\n",
        "ham_words = //TODO\n",
        "print(ham_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LVG8kjbZHod"
      },
      "source": [
        "# calculate the prior of a message being spam or non-spam\n",
        "\n",
        "ham_prob = //TODO\n",
        "spam_prob = //TODO\n",
        "\n",
        "print('probability of a message being ham: ',ham_prob)\n",
        "print('probability of a message being spam: ',spam_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUhG4O0RwxyA"
      },
      "source": [
        "Calculate the frequencies (counts) for all words given a category (spam or ham) and also one of the normalizing factors (number of word occurences in the category, meaning the sum of the frequencies of all words in a category)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlNkTk18b9q7"
      },
      "source": [
        "def get_word_counts_for_class(words):\n",
        "    word_df = pd.DataFrame({'words':words})\n",
        "\n",
        "    # calculate the frequencies for each word in the data frame\n",
        "    word_counts = //TODO \n",
        "\n",
        "    # add up all word counts (frequencies)\n",
        "    words_num = word_counts.to_numpy().sum()\n",
        "    print('number of words: '+str(word_counts.count()))\n",
        "    print('number of word occurences: ' + str(words_num)+ '\\n')\n",
        "\n",
        "    # for better interpretability rename columns\n",
        "    word_counts = word_counts.reset_index()\n",
        "    word_counts.columns = ['words','counts']\n",
        "\n",
        "    print('words with the heighest count:')\n",
        "    print(word_counts[:10])\n",
        "    print('>----------------------<')\n",
        "\n",
        "    # return the counts (frequencies) of words, as well as the sum of all frequencies\n",
        "    return word_counts, float(words_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRt5jkQLUmaf"
      },
      "source": [
        "# calculate the frequency of words in the spam and non-spam categories\n",
        "# use the function implemented above\n",
        "\n",
        "# Attention: we already name the variable probs, \n",
        "# but the normalization of counts is yet to be done\n",
        "spam_word_probs, spam_count_sum = get_word_counts_for_class(spam_words)\n",
        "ham_word_probs, ham_count_sum = get_word_counts_for_class(ham_words)\n",
        "\n",
        "# concatenate the spam and non-spam words\n",
        "# and calculate the number of words in the vocabulary\n",
        "spam_words_selected = spam_word_probs['words'].to_numpy()\n",
        "ham_words_selected = ham_word_probs['words'].to_numpy()\n",
        "vocabulary = //TODO\n",
        "num_words_voc = len(vocabulary)\n",
        "\n",
        "print('number of words in the vocabulary')\n",
        "print(num_words_voc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf4IhH8S10Za"
      },
      "source": [
        "# calculate word probabilities for categories spam and non-spam:\n",
        "# Laplace smoothing for naive Bayes (normalize the counts)\n",
        "spam_word_probs['probs'] = //TODO\n",
        "print(spam_word_probs.head())\n",
        "\n",
        "ham_word_probs['probs'] = //TODO\n",
        "print(ham_word_probs.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jrcljdl925l"
      },
      "source": [
        "# write a function to get a log-probability of a chosen word belonging to the category\n",
        "def get_logprob(word, frame, word_count, voc_size, otherframe):\n",
        "\n",
        "    # if the word was encountered in the category:\n",
        "    row =  frame.loc[frame['words'] == word]\n",
        "    if not(row.empty):\n",
        "        return //TODO\n",
        "    \n",
        "    # if the word was not encountered (count=0) in a category, \n",
        "    # but is part of the vocabulary\n",
        "    row = otherframe.loc[otherframe['words'] == word]\n",
        "    if not(row.empty):\n",
        "        return np.log(1./(word_count+voc_size))\n",
        "\n",
        "    return 0\n",
        "\n",
        "# test for the word 'call' the probability of a message being spam or not\n",
        "print(get_logprob('call',spam_word_probs, spam_count_sum, num_words_voc, ham_word_probs))\n",
        "print(get_logprob('call',ham_word_probs, ham_count_sum, num_words_voc, spam_word_probs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_JFsGZ56QK8"
      },
      "source": [
        "# test message for spam using Naive Bayes approach\n",
        "def predict_message_labels(message):\n",
        "    # calculate the probability of a message being spam\n",
        "    words = message.split(' ')\n",
        "\n",
        "    # get the probabilities of single words\n",
        "    spam_word_logprobs_m = list(map(lambda x: \n",
        "                                    get_logprob(x,spam_word_probs, \n",
        "                                                spam_count_sum, num_words_voc, \n",
        "                                                ham_word_probs),words))\n",
        "    # calculate the message probability given word probabilities\n",
        "    spam_logprob_m = //TODO\n",
        "    \n",
        "    # calculate the probability of a message being ham\n",
        "    ham_word_logprobs_m = list(map(lambda x: \n",
        "                                   get_logprob(x,ham_word_probs,\n",
        "                                               ham_count_sum, num_words_voc, \n",
        "                                               spam_word_probs),words))\n",
        "    ham_logprob_m = //TODO\n",
        "   \n",
        "    # decide\n",
        "    //TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJX6JmyX_yAO"
      },
      "source": [
        "# pick a random text example, print the text and label and check the prediction\n",
        "\n",
        "example = df['text'][22]\n",
        "print(example)\n",
        "print('true label: ',df['label_int'][22])\n",
        "print('predicted label: ',predict_message_labels(example))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC59evV6FZLM"
      },
      "source": [
        "# apply the prediction method to all messages in the x_train and check the accuracy\n",
        "train_preds = x_train.apply(predict_message_labels)\n",
        "print('accuracy for the trainset:')\n",
        "((train_preds==y_train).sum())/len(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz8681au0HvE"
      },
      "source": [
        "Visualize your results: check how many messages have been classified correctly, or misclassified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75QGVzJQr2DP"
      },
      "source": [
        "def visualize_confusion_matrix(true_vals, pred_vals):\n",
        "    cm = confusion_matrix(true_vals, pred_vals)\n",
        "    index = ['predicted ham', 'predicted spam']  \n",
        "    columns = ['ham', 'spam']  \n",
        "    cm_df = pd.DataFrame(cm,columns,index)                      \n",
        "    fig, ax = plt.subplots(figsize=(10,6))  \n",
        "    sns.heatmap(cm_df,annot=True,cmap='Blues', fmt='g')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUhMBoizy2HF"
      },
      "source": [
        "visualize_confusion_matrix(y_train, train_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xur1Yofr0SPo"
      },
      "source": [
        "Do the same for your test set on which you have not trained to actually validate the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VVOr4d1y8V8"
      },
      "source": [
        "test_preds = x_test.apply(predict_message_labels)\n",
        "test_acc = ((test_preds==y_test).sum())/len(y_test)\n",
        "print('accuracy for the testset: ',test_acc)\n",
        "\n",
        "visualize_confusion_matrix(y_test, test_preds)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}