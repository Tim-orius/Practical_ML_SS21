{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tim-orius/Practical_ML_SS21/blob/notebook1/week01/Naive_Bayes_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRcUNm8sWmdc"
      },
      "source": [
        "# Naive Bayes and SMS Spam Collection Dataset\n",
        "\n",
        "In this week we will use Naive Bayes (the assumption of feature independence in a probabilistic context) in order to accomplish a classification task of distinguishing spam from non-spam messages.\n",
        "\n",
        "We will use the kaggle SMS Spam Collection dataset for this purpose: https://www.kaggle.com/uciml/sms-spam-collection-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0TcfBsVaC6Y"
      },
      "source": [
        "First, let us import the packages that we will need. Notice that we are importing nltk - which is a Natural Language Toolkit which will aid us in preprocessing the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RqlUlHgkaeT",
        "outputId": "bdbda45a-414d-44ad-9857-3bed60eea046",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# please restart the runtime after running this cell (to use the versioned matplotlib)\n",
        "!pip install matplotlib==3.1.0"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib==3.1.0 in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.0) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.0) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.0) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.1.0) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.0) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui9qJOP7vcOL",
        "outputId": "16574ea8-f3b3-438c-87b9-fbb20547d622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import string\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "!pip install wget\n",
        "import wget"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqVGT0TyzMqz"
      },
      "source": [
        "# download the data\n",
        "url = \"https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv\"\n",
        "data = wget.download(url)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGjVEheJaixA"
      },
      "source": [
        "We will convert the data into the pandas dataframe and remove the columns we do not need. We will add an additional column with labels, converted to integers (instead of strings 'spam' and 'ham')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N987w8dzvmmW",
        "outputId": "3e166aca-8669-4764-8235-0f6d1f27c45b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "df = pd.read_csv('./spam.csv', encoding = 'latin-1')\n",
        "# delete columns with unuseful values\n",
        "df = df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1)\n",
        "df.columns = ['label', 'text']\n",
        "\n",
        "# convert string labels to integers\n",
        "df[\"label_int\"] = np.NaN\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "  # spam = 1, no spam = 0\n",
        "  df['label_int'] = 0 if df.iloc[idx,0] == 'ham' else 1\n",
        "\n",
        "df.head(n=10)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label                                               text  label_int\n",
              "0   ham  Go until jurong point, crazy.. Available only ...          0\n",
              "1   ham                      Ok lar... Joking wif u oni...          0\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          0\n",
              "3   ham  U dun say so early hor... U c already then say...          0\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...          0\n",
              "5  spam  FreeMsg Hey there darling it's been 3 week's n...          0\n",
              "6   ham  Even my brother is not like to speak with me. ...          0\n",
              "7   ham  As per your request 'Melle Melle (Oru Minnamin...          0\n",
              "8  spam  WINNER!! As a valued network customer you have...          0\n",
              "9  spam  Had your mobile 11 months or more? U R entitle...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f523a72a-8331-40ce-939b-961bd306982d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>label_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f523a72a-8331-40ce-939b-961bd306982d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f523a72a-8331-40ce-939b-961bd306982d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f523a72a-8331-40ce-939b-961bd306982d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT0slQajdLAw"
      },
      "source": [
        "As a preprocessing step, we have to clean the dataset. This is because not all sms-symbols are relevant for spam classification. For example, punctuation is not. Consider also that word endings, e.g. singular or plural, might hinder to recognize the word as the same (and update the count accordingly)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxgoDWLk9ikW"
      },
      "source": [
        "# the cleanTest function is from \n",
        "# https://www.kaggle.com/ishansoni/sms-spam-collection-dataset\n",
        "\n",
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def cleanText(message):\n",
        "    \n",
        "    # remove the punctuation from the messages\n",
        "    # hint1: use maketrans method of str\n",
        "    # hint2: you can get punctuation characters with string.punctuation (print those to check)\n",
        "    message = message.translate(//TODO)\n",
        "    # convert words in the message into their stems and remove stopwords\n",
        "    # also remove numbers hint: isdigit() method could be useful\n",
        "    words = [//TODO]\n",
        "    \n",
        "    return \" \".join(words)\n",
        "\n",
        "df[\"text\"] = df[\"text\"].apply(cleanText)\n",
        "df.head(n = 10)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i20gJjt2wW4N"
      },
      "source": [
        "Split the data into train and test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NipVNb5TF8RV"
      },
      "source": [
        "x = df[\"text\"]\n",
        "y = df[\"label_int\"]\n",
        "\n",
        "perm = np.random.permutation(len(x))\n",
        "\n",
        "split = 0.8\n",
        "\n",
        "x_train, x_test = x[perm[:int(split*len(x))]], x[perm[int(split*len(x)):]]\n",
        "y_train, y_test = y[perm[:int(split*len(y))]], y[perm[int(split*len(y)):]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zies0r53wbuV"
      },
      "source": [
        "Gather all spam words in a list and all ham words in another list. \n",
        "\n",
        "Hint: a message consists of words. Join the messages into a global string and then split them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzbIAt2ZPlfT"
      },
      "source": [
        "# 0 - ham, 1 - spam\n",
        "# select all train spam messages\n",
        "spam_messages = //TODO\n",
        "# join them and split into a list of single words\n",
        "spam_words = //TODO\n",
        "print(spam_words)\n",
        "\n",
        "# repeat for ham messages\n",
        "ham_messages = //TODO\n",
        "ham_words = //TODO\n",
        "print(ham_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LVG8kjbZHod"
      },
      "source": [
        "# calculate the prior of a message being spam or non-spam\n",
        "\n",
        "ham_prob = //TODO\n",
        "spam_prob = //TODO\n",
        "\n",
        "print('probability of a message being ham: ',ham_prob)\n",
        "print('probability of a message being spam: ',spam_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUhG4O0RwxyA"
      },
      "source": [
        "Calculate the frequencies (counts) for all words given a category (spam or ham) and also one of the normalizing factors (number of word occurences in the category, meaning the sum of the frequencies of all words in a category)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlNkTk18b9q7"
      },
      "source": [
        "def get_word_counts_for_class(words):\n",
        "    word_df = pd.DataFrame({'words':words})\n",
        "\n",
        "    # calculate the frequencies for each word in the data frame\n",
        "    word_counts = //TODO \n",
        "\n",
        "    # add up all word counts (frequencies)\n",
        "    words_num = word_counts.to_numpy().sum()\n",
        "    print('number of words: '+str(word_counts.count()))\n",
        "    print('number of word occurences: ' + str(words_num)+ '\\n')\n",
        "\n",
        "    # for better interpretability rename columns\n",
        "    word_counts = word_counts.reset_index()\n",
        "    word_counts.columns = ['words','counts']\n",
        "\n",
        "    print('words with the heighest count:')\n",
        "    print(word_counts[:10])\n",
        "    print('>----------------------<')\n",
        "\n",
        "    # return the counts (frequencies) of words, as well as the sum of all frequencies\n",
        "    return word_counts, float(words_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRt5jkQLUmaf"
      },
      "source": [
        "# calculate the frequency of words in the spam and non-spam categories\n",
        "# use the function implemented above\n",
        "\n",
        "# Attention: we already name the variable probs, \n",
        "# but the normalization of counts is yet to be done\n",
        "spam_word_probs, spam_count_sum = get_word_counts_for_class(spam_words)\n",
        "ham_word_probs, ham_count_sum = get_word_counts_for_class(ham_words)\n",
        "\n",
        "# concatenate the spam and non-spam words\n",
        "# and calculate the number of words in the vocabulary\n",
        "spam_words_selected = spam_word_probs['words'].to_numpy()\n",
        "ham_words_selected = ham_word_probs['words'].to_numpy()\n",
        "vocabulary = //TODO\n",
        "num_words_voc = len(vocabulary)\n",
        "\n",
        "print('number of words in the vocabulary')\n",
        "print(num_words_voc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf4IhH8S10Za"
      },
      "source": [
        "# calculate word probabilities for categories spam and non-spam:\n",
        "# Laplace smoothing for naive Bayes (normalize the counts)\n",
        "spam_word_probs['probs'] = //TODO\n",
        "print(spam_word_probs.head())\n",
        "\n",
        "ham_word_probs['probs'] = //TODO\n",
        "print(ham_word_probs.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jrcljdl925l"
      },
      "source": [
        "# write a function to get a log-probability of a chosen word belonging to the category\n",
        "def get_logprob(word, frame, word_count, voc_size, otherframe):\n",
        "\n",
        "    # if the word was encountered in the category:\n",
        "    row =  frame.loc[frame['words'] == word]\n",
        "    if not(row.empty):\n",
        "        return //TODO\n",
        "    \n",
        "    # if the word was not encountered (count=0) in a category, \n",
        "    # but is part of the vocabulary\n",
        "    row = otherframe.loc[otherframe['words'] == word]\n",
        "    if not(row.empty):\n",
        "        return np.log(1./(word_count+voc_size))\n",
        "\n",
        "    return 0\n",
        "\n",
        "# test for the word 'call' the probability of a message being spam or not\n",
        "print(get_logprob('call',spam_word_probs, spam_count_sum, num_words_voc, ham_word_probs))\n",
        "print(get_logprob('call',ham_word_probs, ham_count_sum, num_words_voc, spam_word_probs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_JFsGZ56QK8"
      },
      "source": [
        "# test message for spam using Naive Bayes approach\n",
        "def predict_message_labels(message):\n",
        "    # calculate the probability of a message being spam\n",
        "    words = message.split(' ')\n",
        "\n",
        "    # get the probabilities of single words\n",
        "    spam_word_logprobs_m = list(map(lambda x: \n",
        "                                    get_logprob(x,spam_word_probs, \n",
        "                                                spam_count_sum, num_words_voc, \n",
        "                                                ham_word_probs),words))\n",
        "    # calculate the message probability given word probabilities\n",
        "    spam_logprob_m = //TODO\n",
        "    \n",
        "    # calculate the probability of a message being ham\n",
        "    ham_word_logprobs_m = list(map(lambda x: \n",
        "                                   get_logprob(x,ham_word_probs,\n",
        "                                               ham_count_sum, num_words_voc, \n",
        "                                               spam_word_probs),words))\n",
        "    ham_logprob_m = //TODO\n",
        "   \n",
        "    # decide\n",
        "    //TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJX6JmyX_yAO"
      },
      "source": [
        "# pick a random text example, print the text and label and check the prediction\n",
        "\n",
        "example = df['text'][22]\n",
        "print(example)\n",
        "print('true label: ',df['label_int'][22])\n",
        "print('predicted label: ',predict_message_labels(example))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC59evV6FZLM"
      },
      "source": [
        "# apply the prediction method to all messages in the x_train and check the accuracy\n",
        "train_preds = x_train.apply(predict_message_labels)\n",
        "print('accuracy for the trainset:')\n",
        "((train_preds==y_train).sum())/len(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz8681au0HvE"
      },
      "source": [
        "Visualize your results: check how many messages have been classified correctly, or misclassified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75QGVzJQr2DP"
      },
      "source": [
        "def visualize_confusion_matrix(true_vals, pred_vals):\n",
        "    cm = confusion_matrix(true_vals, pred_vals)\n",
        "    index = ['predicted ham', 'predicted spam']  \n",
        "    columns = ['ham', 'spam']  \n",
        "    cm_df = pd.DataFrame(cm,columns,index)                      \n",
        "    fig, ax = plt.subplots(figsize=(10,6))  \n",
        "    sns.heatmap(cm_df,annot=True,cmap='Blues', fmt='g')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUhMBoizy2HF"
      },
      "source": [
        "visualize_confusion_matrix(y_train, train_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xur1Yofr0SPo"
      },
      "source": [
        "Do the same for your test set on which you have not trained to actually validate the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VVOr4d1y8V8"
      },
      "source": [
        "test_preds = x_test.apply(predict_message_labels)\n",
        "test_acc = ((test_preds==y_test).sum())/len(y_test)\n",
        "print('accuracy for the testset: ',test_acc)\n",
        "\n",
        "visualize_confusion_matrix(y_test, test_preds)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}